---
image: 20190607-vln-teaser.png
title: Tactical Rewind&#58; Self-Correction via Backtracking in Vision-and-Language Navigation
excerpt: The agent learns to follow natural language instructions to navigate  in previously unseen house. We propose to combine neural network and search. We use local signals to act greedily and global signals to backtrack when exploring the environment. Our framework is simple and can be applied to any seq2seq agent with no training required. We achieved new SoTA at the time of submission. 
author: <b>Liyiming Ke</b>, Xiujun Li, Yonatan Bisk, Ari Holtzman, Zhe Gan, Jingjing Liu, Jianfeng Gao, Yejin Choi, Siddhartha Srinivasa.
venue: Computer Vision and Pattern Recognition (CVPR)
year: 2019
tags: vision language navigation search
arxiv: https://arxiv.org/abs/1903.02547
code: https://github.com/kelym/fast
poster: 20190607-vln.pdf
bibtype: inproceedings
bibname: ke2019tactile
bibauthor: Ke, Liyiming and Li, Xiujun and Bisk, Yonatan and Holtzman, Ari and Gan, Zhe and Liu, Jingjing and Gao, Jianfeng and Choi, Yejin and Srinivasa, Siddhartha
bibbook: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
---

